# Apache-pyspark-hadoop-using-databricks
Explains some basic activities performed using pyspark and executing some machine learning (ML) algorithms using MLlib API


The notebooks which was posted on this repository was developed using databricks ,  which is an open source platform created by the spark founder , as a choice you can choose some other platforms which is mentioned below :

1)Using ubuntu on virtual machine/local machine (or)

2)AWS EC2 (or)

3)AWS EMR (or)

4)Data bricks.

For executing the notebook in this github repo using data bricks , kindly create an community edition account and then get started by creating an cluster for your spark environment .


After the above procedure step into the notebook section , select the cluster that you had created before , make sure that you had uploaded the input data on the data section in the form of table.

Refer the schema of the input data table and try to change it's datatype according to the rows of each features.

Finally upload the notebook file that you wish to execute on the workspace and you are good to go........
